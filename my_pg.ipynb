{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#create a nerf model\n",
    "input_ch = 3\n",
    "#? What's input_ch_views?\n",
    "input_ch_views = 3\n",
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.keras.Input(shape = input_ch + input_ch_views)\n",
    "\n",
    "inputs_pts, inputs_views = tf.split(inputs, [input_ch, input_ch_views], -1)\n",
    "# display(inputs_pts.shape, \",\", inputs_views.shape)\n",
    "inputs_pts.set_shape([None, input_ch])\n",
    "inputs_views.set_shape([None, input_ch_views])\n",
    "# display(inputs_pts.shape, \",\", inputs_views.shape)\n",
    "\n",
    "#outputs: why does output equal to inputs_pts\n",
    "outputs = inputs_pts\n",
    "D = 8\n",
    "W = 256\n",
    "relu = tf.keras.layers.ReLU()\n",
    "def dense(W, act=relu): return tf.keras.layers.Dense(W, activation=act)\n",
    "for i in range(8):\n",
    "    outputs = dense(W)(outputs)\n",
    "    if i in [4]:\n",
    "        outputs = tf.concat([inputs_pts, outputs], -1)\n",
    "useViewDirs = True\n",
    "if useViewDirs:\n",
    "    # what are these outputs?\n",
    "    alpha_out = dense(1, act=None)(outputs)\n",
    "    bottleneck = dense(256, act=None)(outputs)\n",
    "\n",
    "    input_viewdirs = tf.concat([bottleneck, inputs_views], -1)\n",
    "    outputs = input_viewdirs\n",
    "    for i in range(1):\n",
    "        outputs = dense(W//2)(outputs)\n",
    "    outputs = dense(3, act = None)(outputs)\n",
    "    outputs = tf.concat([outputs, alpha_out], -1)\n",
    "else:\n",
    "    output_ch = 4\n",
    "    outputs = dense(output_ch, act = None)(outputs)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "print(model.summary())\n",
    "\n",
    "grad_vars = model.trainable_variables\n",
    "display(grad_vars)\n",
    "# models = {\"model\": model}\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.        , 0.33333334, 0.6666667 , 1.        ], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\narray([[0.        , 0.33333334, 0.6666667 , 1.        ],\n       [0.        , 0.33333334, 0.6666667 , 1.        ],\n       [0.        , 0.33333334, 0.6666667 , 1.        ],\n       [0.        , 0.33333334, 0.6666667 , 1.        ],\n       [0.        , 0.33333334, 0.6666667 , 1.        ]], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "z_vals = tf.linspace(0., 1., 4)\n",
    "z_vals_new = tf.broadcast_to(z_vals, [5,4])\n",
    "display(z_vals)\n",
    "display(z_vals_new)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 3, 9, 10]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# a = np.random.randint(0,10, size=(3,4))\n",
    "# print(a)\n",
    "# # norms = tf.linalg.norm(a, axis=-1)\n",
    "# # print(norms)\n",
    "# cump = tf.math.cumprod(a, axis=-1)\n",
    "# print(cump)\n",
    "\n",
    "display([2,3] + [9,10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 63 0 <class 'int'> <class 'int'> False\n",
      "(None, 63) (None, 63) (None, 0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-c3d9ed5850bb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    243\u001B[0m         \u001B[0;31m# display(\"batch: \", batch, \", batch_rays: \", batch_rays, \", target_s\", target_s)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    244\u001B[0m         \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 245\u001B[0;31m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-5-c3d9ed5850bb>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    167\u001B[0m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconfig_parser\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    168\u001B[0m     \u001B[0margs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 169\u001B[0;31m     render_kwargs_train, render_kwargs_test, start, grad_vars, models = create_nerf(\n\u001B[0m\u001B[1;32m    170\u001B[0m             args)\n\u001B[1;32m    171\u001B[0m     \u001B[0mlrate\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlrate\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/nerf_study/nerf/run_nerf.py\u001B[0m in \u001B[0;36mcreate_nerf\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m    395\u001B[0m         input_ch_views=input_ch_views, use_viewdirs=args.use_viewdirs)\n\u001B[1;32m    396\u001B[0m     \u001B[0mgrad_vars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 397\u001B[0;31m     \u001B[0mmodels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m'model'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    398\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    399\u001B[0m     \u001B[0mmodel_fine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/nerf_study/nerf/run_nerf.py\u001B[0m in \u001B[0;36mcreate_nerf\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m    395\u001B[0m         input_ch_views=input_ch_views, use_viewdirs=args.use_viewdirs)\n\u001B[1;32m    396\u001B[0m     \u001B[0mgrad_vars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 397\u001B[0;31m     \u001B[0mmodels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m'model'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    398\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    399\u001B[0m     \u001B[0mmodel_fine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1158\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1159\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1160\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1161\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1162\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1173\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1174\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1175\u001B[0;31m                 \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1176\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1177\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from nerf.run_nerf_helpers import sample_pdf, img2mse, mse2psnr\n",
    "from nerf.run_nerf import create_nerf, config_parser\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from load_llff import load_llff_data\n",
    "data_dir = \"./data/nerf_llff_data/fern/\"\n",
    "# get rays\n",
    "\n",
    "def render_rays(ray_batch, network_query_fn, network_fn, N_samples, retraw=False, N_importance=10, lindisp=False, perturb=0., network_fine=None, white_bkgd=False, raw_noise_std = 0., verbose=False):\n",
    "\n",
    "    def raw2outputs(raw, z_vals, rays_d):\n",
    "        def raw2alpla(raw, dists, act_fn = tf.nn.relu):\n",
    "            return 1.0 - tf.exp(-act_fn(raw) * dists)\n",
    "        # ???\n",
    "        dists = z_vals[..., 1:] - z_vals[..., -1:]\n",
    "        # ???\n",
    "        dists = tf.concat([dists, tf.broadcast_to([1e10], dists[..., :1].shape)], axis=-1)\n",
    "        dists = dists * tf.linalg.norm(rays_d[..., None, :], axis=-1)\n",
    "        rgb = tf.math.sigmoid(raw[..., :3])\n",
    "\n",
    "        noise = 0.\n",
    "        if(raw_noise_std > 0):\n",
    "            noise = tf.random.normal(raw[..., :3].shape) * raw_noise_std\n",
    "        #     ???\n",
    "        alpha = raw2alpla(raw[..., 3] + noise, dists)\n",
    "        # ???\n",
    "        weights = alpha * tf.math.cumprod(1.-alpha + 1e-10, axis=-1, exclusive=True)\n",
    "        rgb_map = tf.reduce_sum(weights[..., None] * rgb, axis=-2)\n",
    "        depth_map = tf.reduce_sum(weights * z_vals, axis=-1)\n",
    "        disp_map = 1./tf.maximum(1e-10, depth_map/tf.reduce_sum(weights, axis=-1))\n",
    "        acc_map = tf.reduce_sum(weights, axis=-1)\n",
    "        if white_bkgd:\n",
    "            rgb_map = rgb_map + (1 - acc_map[..., None])\n",
    "        return rgb_map, disp_map, acc_map, weights, depth_map\n",
    "\n",
    "    N_rays = ray_batch.shape[0]\n",
    "    rays_o, rays_d = ray_batch[:, 0:3], ray_batch[:, 3:6]\n",
    "    # ???\n",
    "    viewdirs = ray_batch[:, -3:] if ray_batch.shape[-1] > 8 else None\n",
    "    bounds = tf.reshape(ray_batch[..., 6:8], [-1, 1, 2])\n",
    "    near, far = bounds[..., 0], bounds[..., 1]\n",
    "\n",
    "    t_vals = tf.linspace(0., 1., N_samples)\n",
    "    if not lindisp:\n",
    "        z_vals = near * (1.-t_vals) + far * (t_vals)\n",
    "    else:\n",
    "        z_vals = 1 / (1/near * (1.-t_vals) + 1/far * (t_vals))\n",
    "    z_vals = tf.broadcast_to(z_vals, [N_rays, N_samples])\n",
    "    # print(z_vals.shape)\n",
    "    # if perturb > 0.:\n",
    "        # todo\n",
    "    rays_d_new = rays_d[..., None, :]\n",
    "    z_vals_new = z_vals[..., : , None]\n",
    "    # print(rays_d_new * z_vals_new)\n",
    "\n",
    "    pts = rays_o[..., None, :] + rays_d[..., None, :] * z_vals[..., : , None]\n",
    "    raw = network_query_fn(pts, viewdirs, network_fn)\n",
    "    rgb_map, disp_map, acc_map, weights, depth_map = raw2outputs(\n",
    "        raw, z_vals, rays_d)\n",
    "    if N_importance > 0:\n",
    "        rgb_map_0, disp_map_0, acc_map_0 = rgb_map, disp_map, acc_map\n",
    "        z_vals_mid = .5 * (z_vals[..., 1:] + z_vals[..., -1:])\n",
    "        z_samples = sample_pdf(z_vals_mid, weights[..., 1:-1], N_importance, det = (perturb == 0.))\n",
    "        z_samples = tf.stop_gradient(z_samples)\n",
    "        z_vals = tf.sort(tf.concat([z_vals, z_samples], -1), -1)\n",
    "        pts = rays_o[..., None, :] + rays_d[..., None, :] + z_vals[..., :, None]\n",
    "\n",
    "        run_fn = network_fn if network_fine is None else network_fine\n",
    "        raw = network_query_fn(pts, viewdirs, run_fn)\n",
    "        rgb_map, disp_map, acc_map, weights, depth_map = raw2outputs(\n",
    "            raw, z_vals, rays_d)\n",
    "\n",
    "    ret = {'rgb_map': rgb_map, 'disp_map': disp_map, 'acc_map': acc_map}\n",
    "\n",
    "    if retraw:\n",
    "        ret['raw'] = raw\n",
    "    if N_importance > 0:\n",
    "        ret['rgb0'] = rgb_map_0\n",
    "        ret['disp0'] = disp_map_0\n",
    "        ret['acc0'] = acc_map_0\n",
    "        ret['z_std'] = tf.math.reduce_std(z_samples, -1)  # [N_rays]\n",
    "\n",
    "    for k in ret:\n",
    "        tf.debugging.check_numerics(ret[k], 'output {}'.format(k))\n",
    "\n",
    "    return ret\n",
    "\n",
    "def batchify_rays(rays_flat, chunk, **kwargs):\n",
    "    all_ret = {}\n",
    "    for i in range(0, rays_flat.shape[0], chunk):\n",
    "        ret = render_rays(rays_flat[i:i+chunk], **kwargs)\n",
    "        for k in ret:\n",
    "            if k not in all_ret:\n",
    "                all_ret[k] = []\n",
    "            all_ret[k].append(ret[k])\n",
    "    all_ret = {k: tf.concat(all_ret[k], 0) for k in all_ret}\n",
    "    return all_ret\n",
    "\n",
    "def get_rays(H, W, focal, c2w):\n",
    "    i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy')\n",
    "    dirs = tf.stack([(i - W*.5)/focal, -(j - H*.5)/focal, -tf.ones_like(i)], -1)\n",
    "    print(c2w)\n",
    "    # Why needs to transform from camera to world\n",
    "    rays_d = tf.reduce_sum(dirs[..., np.newaxis, :] * c2w[:3, :3], -1)\n",
    "    # why origin is the c2w?\n",
    "    rays_o = tf.broadcast_to(c2w[:3, -1], np.shape(rays_d))\n",
    "    # print(\"c2w[:3, -1] shape: \", c2w[:3, -1], \", rays_o shape: \", rays_o.shape)\n",
    "    return rays_d, rays_o\n",
    "\n",
    "def render(H, W, focal, chunk=1024, rays=None, c2w=None, ndc=None, near=0., far=1., use_viewdirs=False, c2w_staticcam=None, **kwargs):\n",
    "    if c2w:\n",
    "        rays_d, rays_o = get_rays(H, W, focal, c2w)\n",
    "    else:\n",
    "        rays_d, rays_o = rays\n",
    "    if use_viewdirs:\n",
    "        viewdirs = rays_d\n",
    "        if c2w_staticcam:\n",
    "            rays_d, rays_o = get_rays(H, W, focal, c2w_staticcam)\n",
    "        viewdirs = viewdirs / tf.linalg.norm(viewdirs, axis=-1, keepdims=True)\n",
    "        viewdirs = tf.cast(tf.reshape(viewdirs, [-1,3]), dtype=tf.float32)\n",
    "    sh = rays_d.shape\n",
    "#        todo ndc\n",
    "    rays_o = tf.cast(tf.reshape(rays_o, [-1, 3]), dtype=tf.float32)\n",
    "    rays_d = tf.cast(tf.reshape(rays_d, [-1, 3]), dtype=tf.float32)\n",
    "\n",
    "    near = near * tf.ones_like(rays_d[..., :1])\n",
    "    far = far * tf.ones_like(rays_d[..., :1])\n",
    "    rays = tf.concat([rays_o, rays_d, near, far], axis=-1)\n",
    "    # display(\"rays.shape: \", rays.shape, \"viewdirs.shape\", viewdirs.shape)\n",
    "    if use_viewdirs:\n",
    "        rays = tf.concat([rays, viewdirs], axis=-1)\n",
    "    all_ret = batchify_rays(rays, chunk, **kwargs)\n",
    "    for k in all_ret:\n",
    "        # ???\n",
    "        k_sh = list(sh[:-1]) + list(all_ret[k].shape[1:])\n",
    "        all_ret[k] = tf.reshape(all_ret[k], k_sh)\n",
    "    k_extract = ['rgb_map', 'disp_map', 'acc_map']\n",
    "    ret_list = [all_ret[k] for k in k_extract]\n",
    "    ret_dict = {k:all_ret[k] for k in all_ret if k not in k_extract}\n",
    "    return ret_list + [ret_dict]\n",
    "\n",
    "def normalize(x):\n",
    "    return x / np.linalg.norm(x)\n",
    "\n",
    "def viewmatrix(z, up, pos):\n",
    "    vec2 = normalize(z)\n",
    "    vec1_avg = up\n",
    "    vec0 = normalize(np.cross(vec1_avg, vec2))\n",
    "    vec1 = normalize(np.cross(vec2, vec0))\n",
    "    m = np.stack([vec0, vec1, vec2, pos], 1)\n",
    "    return m\n",
    "\n",
    "\n",
    "def get_rays_np(H, W, focal, c2w):\n",
    "    \"\"\"ray orgin, ray direction\"\"\"\n",
    "    i, j = np.meshgrid(np.arange(W, dtype=np.float32), np.arange(H, dtype=np.float32), indexing='xy')\n",
    "    # here calculate direction\n",
    "    dirs = np.stack([(i-W*.5)/focal, -(j-H*.5)/focal, -np.ones_like(i)], -1)\n",
    "    # todo 2 arrays have different shape, numpy do broadcasting\n",
    "    rays_d = np.sum(dirs[..., np.newaxis, :] * c2w[:3, :3], -1)\n",
    "    rays_o = np.broadcast_to(c2w[:3, -1], np.shape(rays_d))\n",
    "    return rays_o, rays_d\n",
    "\n",
    "def train():\n",
    "    # create nerf model\n",
    "    parser = config_parser()\n",
    "    args = parser.parse_args()\n",
    "    render_kwargs_train, render_kwargs_test, start, grad_vars, models = create_nerf(\n",
    "            args)\n",
    "    lrate = args.lrate\n",
    "    optimizer = tf.keras.optimizers.Adam(lrate)\n",
    "    models['optimizer'] = optimizer\n",
    "\n",
    "    images, poses, bds, render_poses, i_test = load_llff_data(data_dir, 8,\n",
    "                                                                      recenter=True, bd_factor=.75,\n",
    "                                                                      spherify=True)\n",
    "\n",
    "    chunk = 1024\n",
    "    hwf = poses[0, :3, -1]\n",
    "    H, W, focal = hwf\n",
    "    H, W = int(H), int(W)\n",
    "    hwf = [H, W, focal]\n",
    "\n",
    "    # display(\"c2w: \", poses[:, :3, :4])\n",
    "    #todo what's c2w=poses[:, :3, :4]?\n",
    "    rays = [get_rays_np(H, W, focal, p) for p in poses[:, :3, :4]] #return 2 kinds of data of 20 picturs': 1. directions 2. direction origins\n",
    "    rays = np.stack(rays, axis=0)\n",
    "    # rays.shape: 20, 2, 378, 504, 3\n",
    "\n",
    "    rays_rgb = np.concatenate([rays, images[:, None, ...]], 1)\n",
    "    # display(\"rays.shape: \", rays.shape, \", rays_rgb.shape: \", rays_rgb.shape): (20, 2, 378, 504, 3), (20, 3, 378, 504, 3)\n",
    "    rays_rgb = np.transpose(rays_rgb, [0, 2, 3, 1, 4])\n",
    "    # print(rays_rgb.shape): 20 pictures, every pixel, channel(3), origin(3), direction(3)\n",
    "\n",
    "    # slicing, so 0, 8, 16  are for testing\n",
    "    i_test = np.arange(images.shape[0])[::8]\n",
    "    i_val = i_test\n",
    "    i_train = np.array([i for i in np.arange(int(images.shape[0])) if\n",
    "                                (i not in i_test and i not in i_val)])\n",
    "\n",
    "    rays_rgb = np.stack([rays_rgb[i] for i in i_train], axis=0)\n",
    "    # display(\"rays_rgb shape\", rays_rgb.shape): (17, 378, 504, 3, 3)\n",
    "    rays_rgb = np.reshape(rays_rgb, [-1, 3, 3])\n",
    "    # display(\"rays_rgb shape\", rays_rgb.shape) : (3238704, 3, 3)\n",
    "\n",
    "    rays_rgb = rays_rgb.astype(np.float32)\n",
    "    np.random.shuffle(rays_rgb)\n",
    "\n",
    "    i_batch = 0\n",
    "    N_iters = 1\n",
    "    N_rand = 5\n",
    "    use_batching = not args.no_batching\n",
    "\n",
    "    for i in range(start, N_iters):\n",
    "        # here always use batch\n",
    "        batch = rays_rgb[i_batch:i_batch + N_rand]\n",
    "        batch = np.transpose(batch, [1, 0, 2])\n",
    "        # what's target?\n",
    "        batch_rays, target_s = batch[:2], batch[2]\n",
    "\n",
    "        i_batch += N_rand\n",
    "        if i_batch > rays_rgb.shape[0]:\n",
    "            np.random.shuffle(rays_rgb)\n",
    "            i_batch = 0\n",
    "        with tf.GradientTape() as tape:\n",
    "            render_kwargs_train['N_importance'] = 10\n",
    "            rgb, disp, acc, extras =render(H, W, focal, chunk, batch_rays, **render_kwargs_train)\n",
    "            img_loss = img2mse(rgb, target_s)\n",
    "            # ????s\n",
    "            trans = extras[\"raw\"][..., -1]\n",
    "            loss = img_loss\n",
    "            psnr = mse2psnr(img_loss)\n",
    "\n",
    "            if 'rgb0' in extras:\n",
    "                img_loss0 = img2mse(extras['rgb0'], target_s)\n",
    "                loss += img_loss0\n",
    "                psnr0 = mse2psnr(img_loss0)\n",
    "\n",
    "            gradients = tape.gradient(loss, grad_vars)\n",
    "            optimizer.apply_gradients(zip(gradients, grad_vars))\n",
    "\n",
    "        # display(\"batch: \", batch, \", batch_rays: \", batch_rays, \", target_s\", target_s)\n",
    "        break\n",
    "train()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
